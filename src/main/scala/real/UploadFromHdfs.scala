package real

import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.{FileSystem, Path}
import sttp.client3._
import sttp.client3.okhttp.OkHttpSyncBackend
import sttp.model.MediaType

import java.io.{File, IOException, InputStream}
import scala.util.{Failure, Success, Try}

object UploadFromHdfs {

  private val bufferSize = 8 * 1024 // 8 KB

  /**
   * Upload d'un fichier pr√©sent sur HDFS vers une URL pr√©sign√©e PUT.
   * 1Ô∏è‚É£ Tente un upload en streaming direct HDFS ‚Üí PUT
   * 2Ô∏è‚É£ Si √©chec, fallback vers copie locale /tmp + upload
   */
  def upload(fs: FileSystem, hdfsPath: Path, presignedUrl: String): Unit = {
    println(s"üîπ Tentative d‚Äôupload en streaming depuis HDFS: ${hdfsPath.toString}")
    Try(uploadStream(fs, hdfsPath, presignedUrl)) match {
      case Success(_) =>
        println(s"‚úÖ Upload r√©ussi en streaming depuis HDFS: ${hdfsPath.getName}")

      case Failure(e) =>
        println(s"‚ö†Ô∏è √âchec du streaming direct (${e.getMessage}), fallback vers copie locale...")
        Try(uploadViaTmp(fs, hdfsPath, presignedUrl)) match {
          case Success(_) =>
            println(s"‚úÖ Upload r√©ussi apr√®s fallback depuis /tmp pour ${hdfsPath.getName}")
          case Failure(e2) =>
            println(s"‚ùå Upload √©chou√© m√™me apr√®s fallback : ${e2.getMessage}")
            throw e2
        }
    }
  }

  /**
   * M√©thode 1 : upload en streaming direct depuis HDFS vers l‚ÄôURL PUT
   */
  private def uploadStream(fs: FileSystem, hdfsPath: Path, presignedUrl: String): Unit = {
    implicit val backend = OkHttpSyncBackend()
    val in: InputStream = fs.open(hdfsPath)

    val TarMediaType: MediaType =
      MediaType.parse("application/x-tar").getOrElse(MediaType.ApplicationOctetStream)

    try {
      val request = basicRequest
        .put(uri"$presignedUrl")
        .contentType("application/x-tar")
        .body(InputStreamBody(in, TarMediaType))
        .readTimeout(scala.concurrent.duration.Duration.Inf) // important pour les gros fichiers

      val response = request.send(backend)

      if (!(response.code.isSuccess))
        throw new IOException(s"Erreur HTTP ${response.code}: ${response.statusText}")

    } finally {
      in.close()
      backend.close()
    }
  }

  /**
   * M√©thode 2 : fallback ‚Äî copie le fichier HDFS vers /tmp, puis upload depuis le local
   */
  private def uploadViaTmp(fs: FileSystem, hdfsPath: Path, presignedUrl: String): Unit = {
    implicit val backend = OkHttpSyncBackend()
    val localFile = new File(s"/tmp/${hdfsPath.getName}")

    try {
      // Copie depuis HDFS
      fs.copyToLocalFile(hdfsPath, new Path(localFile.getAbsolutePath))

      val request = basicRequest
        .put(uri"$presignedUrl")
        .contentType("application/x-tar")
        .body(localFile)
        .readTimeout(scala.concurrent.duration.Duration.Inf)

      val response = request.send(backend)

      if (response.code.isSuccess)
        println(s"‚úÖ Upload r√©ussi depuis /tmp (${localFile.getAbsolutePath})")
      else
        throw new IOException(s"Erreur HTTP ${response.code}: ${response.statusText}")

    } finally {
      backend.close()
      if (localFile.exists()) {
        localFile.delete()
        println(s"üßπ Fichier temporaire supprim√©: ${localFile.getAbsolutePath}")
      }
    }
  }

  /*
  // Exemple d‚Äôutilisation
  val conf = new Configuration()
  conf.set("fs.defaultFS", "hdfs://namenode:8020") // si besoin
  val fs = FileSystem.get(conf)

  val hdfsPath = new Path("/user/data/archive_20251026.tar")
  val presignedUrl = "https://my-s3-presigned-url.example.com/..." // ton URL PUT

  UploadFromHdfs.upload(fs, hdfsPath, presignedUrl)
   */
}
